{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch will use device cuda:0\n",
      "4 2\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import typing\n",
    "from typing import List\n",
    "\n",
    "Parameters = List[torch.nn.parameter.Parameter]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Pytorch will use device {device}\")\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "obs = env.reset()\n",
    "\n",
    "in_dim = len(obs)\n",
    "out_dim = env.action_space.n\n",
    "\n",
    "print(in_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(net: torch.nn.Sequential) -> Parameters:\n",
    "    '''\n",
    "    Gets the parameters from a PyTorch model stored as an nn.Sequential\n",
    "    \n",
    "    @params\n",
    "        network (nn.Sequential): A pytorch model\n",
    "    @returns\n",
    "        Parameters: the parameters of the model\n",
    "    '''\n",
    "    params = []\n",
    "    for layer in net:\n",
    "        if hasattr(layer, 'weight') and layer.weight != None:\n",
    "            params.append(layer.weight)\n",
    "        if hasattr(layer, 'bias') and layer.bias != None:\n",
    "            params.append(layer.bias)\n",
    "    return params\n",
    "\n",
    "\n",
    "def set_params(net: torch.nn.Sequential, params: Parameters) -> torch.nn.Sequential:\n",
    "    '''\n",
    "    Sets the parameters for an nn.Sequential\n",
    "    \n",
    "    @params\n",
    "        network (torch.nn.Sequential): A network to change the parameters of \n",
    "        params (Parameters): Parameters to place into the model\n",
    "    @returns\n",
    "        torch.nn.Sequential: A model the the provided parameters\n",
    "    '''\n",
    "    i = 0\n",
    "    for layerid, layer in enumerate(net):\n",
    "        if hasattr(layer, 'weight') and layer.weight != None:\n",
    "            net[layerid].weight = params[i]\n",
    "            i += 1\n",
    "        if hasattr(layer, 'bias') and layer.bias != None:\n",
    "            net[layerid].bias = params[i]\n",
    "            i += 1\n",
    "    return net\n",
    "\n",
    "def fitness(solution: Parameters, net: torch.nn.Sequential, render=False) -> float:\n",
    "    '''\n",
    "    Evaluate a solution, a set of weights and biases for the network\n",
    "    \n",
    "    @params\n",
    "        solution (Parameters): parameters to test the fitness of\n",
    "        net (torch.nn.Sequential): A network for testing the parameters with\n",
    "        render (bool): whether or not to draw the agent interacting with the environment as it trains\n",
    "    @returns\n",
    "        float: The fitness of the solution\n",
    "    '''\n",
    "    net = set_params(net, solution)\n",
    "    \n",
    "    ob = env.reset()\n",
    "    \n",
    "    done = False\n",
    "    sum_reward = 0\n",
    "    while not done:\n",
    "        ob = torch.tensor(ob).float().unsqueeze(0).to(device)\n",
    "        q_vals = net(ob)\n",
    "        \n",
    "        act = torch.argmax(q_vals.cpu()).item()\n",
    "        \n",
    "        ob_next, reward, done, info = env.step(act)\n",
    "        ob = ob_next\n",
    "    \n",
    "        sum_reward += reward\n",
    "        if render:\n",
    "            env.render()\n",
    "    return sum_reward\n",
    "\n",
    "def select(pop: List[Parameters], fitnesses: np.ndarray) -> List[Parameters]:\n",
    "    '''\n",
    "    Select a new population\n",
    "    \n",
    "    @params\n",
    "        pop (List[Parameters]): The entire population of parameters\n",
    "        fitnesses (np.ndarray): the fitnesses for each entity in the population\n",
    "    @returns\n",
    "        List[Parameters]: A new population made of fitter individuals\n",
    "    '''\n",
    "    idx = np.random.choice(np.arange(POP_SIZE), size=POP_SIZE, replace=True, p=fitnesses/fitnesses.sum())\n",
    "    return [pop[i] for i in idx]\n",
    "\n",
    "def crossover(parent1: Parameters, pop: List[Parameters]) -> Parameters:\n",
    "    '''\n",
    "    Crossover two individuals and produce a child.\n",
    "    \n",
    "    This is done by randomly splitting the weights and biases at each layer for the parents and then\n",
    "    combining them to produce a child\n",
    "    \n",
    "    @params\n",
    "        parent1 (Parameters): A parent that may potentially be crossed over\n",
    "        pop (List[Parameters]): The population of solutions\n",
    "    @returns\n",
    "        Parameters: A child with attributes of both parents or the original parent1\n",
    "    '''\n",
    "    if np.random.rand() < CROSS_RATE:\n",
    "        i = np.random.randint(0, POP_SIZE, size=1)[0]\n",
    "        parent2 = pop[i]\n",
    "        child = []\n",
    "        split = np.random.rand()\n",
    "        \n",
    "        for p1l, p2l in zip(parent1, parent2):\n",
    "            splitpoint = int(len(p1l)*split)\n",
    "            new_param = nn.parameter.Parameter(torch.cat([p1l[:splitpoint], p2l[splitpoint:]]))\n",
    "            child.append(new_param)\n",
    "\n",
    "        return child\n",
    "    else:\n",
    "        return parent1\n",
    "\n",
    "\n",
    "def gen_mutate(shape: torch.Size) -> torch.tensor:\n",
    "    '''\n",
    "    Generate a tensor to use for random mutation of a parameter\n",
    "    \n",
    "    @params\n",
    "        shape (torch.Size): The shape of the tensor to be created\n",
    "    @returns\n",
    "        torch.tensor: a random tensor\n",
    "    '''\n",
    "    return torch.randn(shape).to(device)*MUTATION_FACTOR\n",
    "    \n",
    "def mutate(child: Parameters) -> Parameters:\n",
    "    '''\n",
    "    Mutate a child\n",
    "    \n",
    "    @params\n",
    "        child (Parameters): The original parameters\n",
    "    @returns\n",
    "        Parameters: The mutated child\n",
    "    '''\n",
    "    for i in range(len(child)):\n",
    "        for j in range(len(child[i])):\n",
    "            child[i][j] += gen_mutate(child[i][j].shape)\n",
    "    return child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0: Average Fitness is 9.635 | Max Fitness is 51.0\n",
      "Generation 1: Average Fitness is 11.21 | Max Fitness is 63.0\n",
      "Generation 2: Average Fitness is 14.89 | Max Fitness is 200.0\n",
      "Generation 3: Average Fitness is 21.885 | Max Fitness is 200.0\n",
      "Generation 4: Average Fitness is 35.98 | Max Fitness is 200.0\n",
      "Generation 5: Average Fitness is 71.665 | Max Fitness is 200.0\n",
      "Generation 6: Average Fitness is 94.22 | Max Fitness is 200.0\n",
      "Generation 7: Average Fitness is 135.385 | Max Fitness is 200.0\n",
      "Generation 8: Average Fitness is 179.865 | Max Fitness is 200.0\n",
      "Generation 9: Average Fitness is 192.315 | Max Fitness is 200.0\n",
      "Generation 10: Average Fitness is 194.365 | Max Fitness is 200.0\n",
      "Generation 11: Average Fitness is 198.22 | Max Fitness is 200.0\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# hyperparameters for genetic algorithm\n",
    "POP_SIZE = 100\n",
    "CROSS_RATE = 0.8\n",
    "MUTATION_RATE = 0.01\n",
    "MUTATION_DECAY = 0.99\n",
    "MUTATION_FACTOR = 0.001\n",
    "N_GENERATIONS = 30\n",
    "FITNESS_EARLY_STOP_THRESH = 196\n",
    "\n",
    "# the pytorch neural network to train\n",
    "net = nn.Sequential(nn.Linear(in_dim, 16, bias=True),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Linear(16, 8, bias=True),\n",
    "                    nn.Sigmoid(),\n",
    "                    nn.Linear(8, out_dim, bias=True)).to(device)\n",
    "\n",
    "# get the required parameter shapes\n",
    "base = get_params(net)\n",
    "shapes = [param.shape for param in base]\n",
    "\n",
    "# build a population\n",
    "pop = []\n",
    "for i in range(POP_SIZE):\n",
    "    entity = []\n",
    "    for shape in shapes:\n",
    "        # if fan in and fan out can be calculated (tensor is 2d) then using kaiming uniform initialisation\n",
    "        # as per nn.Linear\n",
    "        # otherwise use uniform initialisation between -0.5 and 0.5\n",
    "        try:\n",
    "            rand_tensor = nn.init.kaiming_uniform_(torch.empty(shape)).to(device)\n",
    "        except ValueError:\n",
    "            rand_tensor = nn.init.uniform_(torch.empty(shape), -0.2, 0.2).to(device)\n",
    "        entity.append((torch.nn.parameter.Parameter(rand_tensor)))\n",
    "    pop.append(entity)\n",
    "\n",
    "# whether or not to render while training (false runs code a lot faster)\n",
    "render = False\n",
    "\n",
    "# the max episodes (200 is the environment default)\n",
    "env._max_episode_steps = 200\n",
    "\n",
    "\n",
    "# train\n",
    "for i in range(N_GENERATIONS):\n",
    "    # get fitnesses\n",
    "    fitnesses = np.array([fitness(entity, net, render) for entity in pop])\n",
    "    # calculate average fitness of population\n",
    "    avg_fitness = fitnesses.sum()/len(fitnesses)\n",
    "    \n",
    "    # print info of generation\n",
    "    print(f\"Generation {i}: Average Fitness is {avg_fitness} | Max Fitness is {fitnesses.max()}\")\n",
    "    \n",
    "    if avg_fitness > FITNESS_EARLY_STOP_THRESH:\n",
    "        break\n",
    "    # select a new population\n",
    "    pop = select(pop, fitnesses)\n",
    "    pop2 = list(pop)\n",
    "    \n",
    "    # go through the population and crossover and mutate\n",
    "    for i in range(len(pop)):\n",
    "        child = crossover(pop[i], pop2)\n",
    "        child = mutate(child)\n",
    "        pop[i] = child\n",
    "        \n",
    "    MUTATION_RATE = MUTATION_RATE*MUTATION_DECAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fitness of selected entity is 1000.0\n",
      "Best performance of selected entity is 1000.0\n"
     ]
    }
   ],
   "source": [
    "env._max_episode_steps = 300\n",
    "\n",
    "fitnesses = np.array([fitness(entity, net, render) for entity in pop])\n",
    "fittest = np.argmax(fitnesses)\n",
    "\n",
    "env._max_episode_steps = 1000\n",
    "\n",
    "test_fitnesses = []\n",
    "for _ in range(10):\n",
    "    test_fitnesses.append(fitness(pop[fittest], net, True))\n",
    "    \n",
    "print(f\"Average fitness of selected entity is {sum(test_fitnesses)/len(test_fitnesses)}\")\n",
    "print(f\"Best performance of selected entity is {max(test_fitnesses)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
